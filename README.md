# DataWrangling-Project-WeRateDogs-Twitter-Archive

## Project Overview
This project is a data wrangling project, which mainly focusess on fixing the Data Quality and Tidiness issues. 
Using python and it libraries you will collect data in the Jupyter Notebook, documenting the steps and the showcasing the data wrangling process.

The dataset that we will be focusing on is the Tweet archive of user @dog_rates, also known as WeRateDogs. WeRateDogs is a Twitter account that rates people's dogs with a humorous comment about the dog. 

## Data Gathering
In this project we have to download or data manually and programmatically. 
twitter_archive: This dataset is provided by the Udacity course.
image_predictions: This dataset is hosted on Udacity's servers and downloaded programatically using the request library. 
tweet_data: This data sets require's you to use Python's Tweepy library and store each tweet's entire set of JSON data in a file called 'tweet_json.txt' file.

## Data Assessing
When assessing we are looking for data quality and lack of tidiness issues. 
Quality issues: Issues like missing, duplicate, or incorrect data.
Untidy data: Structural issues.

## Data Cleaning
After identifying the Quality and Tidiness Issues, we clean the data.



